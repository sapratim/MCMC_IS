n <- 100  # Number of samples
p <- 5    # Number of features
# Generate predictors (features)
X <- matrix(rnorm(n * p), ncol = p)
# Generate true coefficients
theta_true <- c(3, 2, 1, 0, 0)
# Generate response variable
y <- X %*% theta_true + rnorm(n)
lambda <- 1
iter <- 500
mu <- 1.99/(max(eigen(X%*%t(X))$values) + 0.001)
theta_start <- c(7,5,3,9,1)
theta <- matrix(0, nrow = iter, ncol = length(theta_true))
S <- numeric(length = iter)
grad_fn <- function(mat, data, value)
{
grad = t(mat)%*%(mat%*%value - data)
return(grad)
}
prox_func <- function(u, lambda) {       ####  u is a vector
return(sign(u)*sapply(u, FUN=function(x) {max(abs(x)-lambda,0)}))
}
theta[1,] <- theta_start
for (i in 2:iter)
{
gradval <- grad_fn(X, y, theta[i-1,])
z <- prox_func(theta[i-1,] - mu*gradval, mu*lambda)
S1 <- max(max(abs(gradval)) - lambda, 0)
S2 <- abs(t(gradval)%*%theta[i-1,] - sum(abs(theta[i-1,])))
S[i-1] <- max(S1, S2)
theta[i,] <- z
}
iter_nos <- seq(1:iter)
plot(iter_nos, S, type = "l")
set.seed(123)
n <- 100  # Number of samples
p <- 5    # Number of features
# Generate predictors (features)
X <- matrix(rnorm(n * p), ncol = p)
# Generate true coefficients
theta_true <- c(3, 2, 1, 0, 0)
# Generate response variable
y <- X %*% theta_true + rnorm(n)
lambda <- 1
iter <- 50
mu <- 1.99/(max(eigen(X%*%t(X))$values) + 0.001)
theta_start <- c(7,5,3,9,1)
theta <- matrix(0, nrow = iter, ncol = length(theta_true))
S <- numeric(length = iter)
grad_fn <- function(mat, data, value)
{
grad = t(mat)%*%(mat%*%value - data)
return(grad)
}
prox_func <- function(u, lambda) {       ####  u is a vector
return(sign(u)*sapply(u, FUN=function(x) {max(abs(x)-lambda,0)}))
}
theta[1,] <- theta_start
for (i in 2:iter)
{
gradval <- grad_fn(X, y, theta[i-1,])
z <- prox_func(theta[i-1,] - mu*gradval, mu*lambda)
S1 <- max(max(abs(gradval)) - lambda, 0)
S2 <- abs(t(gradval)%*%theta[i-1,] - sum(abs(theta[i-1,])))
S[i-1] <- max(S1, S2)
theta[i,] <- z
}
iter_nos <- seq(1:iter)
plot(iter_nos, S, type = "l")
set.seed(123)
n <- 100  # Number of samples
p <- 5    # Number of features
# Generate predictors (features)
X <- matrix(rnorm(n * p), ncol = p)
# Generate true coefficients
theta_true <- c(3, 2, 1, 0, 0)
# Generate response variable
y <- X %*% theta_true + rnorm(n)
lambda <- 1
iter <- 50
mu <- 1.99/(max(eigen(X%*%t(X))$values) + 0.001)
theta_start <- c(7,5,3,9,1)
theta <- matrix(0, nrow = iter, ncol = length(theta_true))
S <- numeric(length = iter)
grad_fn <- function(mat, data, value)
{
grad = t(mat)%*%(mat%*%value - data)
return(grad)
}
prox_func <- function(u, lambda) {       ####  u is a vector
return(sign(u)*sapply(u, FUN=function(x) {max(abs(x)-lambda,0)}))
}
theta[1,] <- theta_start
for (i in 2:iter)
{
gradval <- grad_fn(X, y, theta[i-1,])
z <- prox_func(theta[i-1,] - mu*gradval, mu*lambda)
S1 <- max(max(abs(gradval)) - lambda, 0)
S2 <- abs(t(gradval)%*%theta[i-1,] - sum(abs(theta[i-1,])))
S[i-1] <- max(S1, S2)
theta[i,] <- z
}
iter_nos <- seq(1:iter)
plot(iter_nos, log(S), type = "l")
set.seed(123)
n <- 100  # Number of samples
p <- 5    # Number of features
# Generate predictors (features)
X <- matrix(rnorm(n * p), ncol = p)
# Generate true coefficients
theta_true <- c(3, 2, 1, 0, 0)
# Generate response variable
y <- X %*% theta_true + rnorm(n)
lambda <- 1
iter <- 500
mu <- 1.99/(max(eigen(X%*%t(X))$values) + 0.001)
theta_start <- c(7,5,3,9,1)
theta <- matrix(0, nrow = iter, ncol = length(theta_true))
S <- numeric(length = iter)
grad_fn <- function(mat, data, value)
{
grad = t(mat)%*%(mat%*%value - data)
return(grad)
}
prox_func <- function(u, lambda) {       ####  u is a vector
return(sign(u)*sapply(u, FUN=function(x) {max(abs(x)-lambda,0)}))
}
theta[1,] <- theta_start
for (i in 2:iter)
{
gradval <- grad_fn(X, y, theta[i-1,])
z <- prox_func(theta[i-1,] - mu*gradval, mu*lambda)
S1 <- max(max(abs(gradval)) - lambda, 0)
S2 <- abs(t(gradval)%*%theta[i-1,] - sum(abs(theta[i-1,])))
S[i-1] <- max(S1, S2)
theta[i,] <- z
}
iter_nos <- seq(1:iter)
plot(iter_nos, log(S), type = "l")
set.seed(123)
n <- 100  # Number of samples
p <- 5    # Number of features
# Generate predictors (features)
X <- matrix(rnorm(n * p), ncol = p)
# Generate true coefficients
theta_true <- c(3, 2, 1, 0, 0)
# Generate response variable
y <- X %*% theta_true + rnorm(n)
lambda <- 1
iter <- 500
mu <- 1.99/(max(eigen(X%*%t(X))$values) + 0.001)
theta_start <- c(7,5,3,9,1)
theta <- matrix(0, nrow = iter, ncol = length(theta_true))
S <- numeric(length = iter)
grad_fn <- function(mat, data, value)
{
grad = - t(mat)%*%(mat%*%value - data)
return(grad)
}
prox_func <- function(u, lambda) {       ####  u is a vector
return(sign(u)*sapply(u, FUN=function(x) {max(abs(x)-lambda,0)}))
}
theta[1,] <- theta_start
for (i in 2:iter)
{
gradval <- grad_fn(X, y, theta[i-1,])
z <- prox_func(theta[i-1,] - mu*gradval, mu*lambda)
S1 <- max(max(abs(gradval)) - lambda, 0)
S2 <- abs(t(gradval)%*%theta[i-1,] - sum(abs(theta[i-1,])))
S[i-1] <- max(S1, S2)
theta[i,] <- z
}
iter_nos <- seq(1:iter)
plot(iter_nos, log(S), type = "l")
View(x_tv_denoised)
set.seed(123)
n <- 100  # Number of samples
p <- 5    # Number of features
# Generate predictors (features)
X <- matrix(rnorm(n * p), ncol = p)
# Generate true coefficients
theta_true <- c(3, 2, 1, 0, 0)
# Generate response variable
y <- X %*% theta_true + rnorm(n)
lambda <- 1
iter <- 500
mu <- 1.99/(max(eigen(X%*%t(X))$values) + 0.001)
theta_start <- c(7,5,3,9,1)
theta <- matrix(0, nrow = iter, ncol = length(theta_true))
S <- numeric(length = iter)
grad_fn <- function(mat, data, value)
{
grad = t(mat)%*%(mat%*%value - data)
return(grad)
}
prox_func <- function(u, lambda) {       ####  u is a vector
return(sign(u)*sapply(u, FUN=function(x) {max(abs(x)-lambda,0)}))
}
theta[1,] <- theta_start
for (i in 2:iter)
{
gradval <- grad_fn(X, y, theta[i-1,])
z <- prox_func(theta[i-1,] - mu*gradval, mu*lambda)
S1 <- max(max(abs(gradval)) - lambda, 0)
S2 <- abs(-t(gradval)%*%theta[i-1,] - sum(abs(theta[i-1,])))
S[i-1] <- max(S1, S2)
theta[i,] <- z
}
iter_nos <- seq(1:iter)
plot(iter_nos, log(S), type = "l")
set.seed(123)
n <- 100  # Number of samples
p <- 5    # Number of features
# Generate predictors (features)
X <- matrix(rnorm(n * p), ncol = p)
# Generate true coefficients
theta_true <- c(3, 2, 1, 0, 0)
# Generate response variable
y <- X %*% theta_true + rnorm(n)
lambda <- 1
iter <- 500
mu <- 1.99/(max(eigen(X%*%t(X))$values) + 0.001)
theta_start <- c(7,5,3,9,1)
theta <- matrix(0, nrow = iter, ncol = length(theta_true))
S <- numeric(length = iter)
grad_fn <- function(mat, data, value)
{
grad = t(mat)%*%(mat%*%value - data)
return(grad)
}
prox_func <- function(u, lambda) {       ####  u is a vector
return(sign(u)*sapply(u, FUN=function(x) {max(abs(x)-lambda,0)}))
}
theta[1,] <- theta_start
for (i in 2:iter)
{
gradval <- grad_fn(X, y, theta[i-1,])
z <- prox_func(theta[i-1,] - mu*gradval, mu*lambda)
S1 <- max(max(abs(gradval)) - lambda, 0)
S2 <- abs(-t(gradval)%*%theta[i-1,] - sum(abs(theta[i-1,])))
S[i-1] <- max(S1, S2)
theta[i,] <- z
}
iter_nos <- seq(1:iter)
plot(iter_nos, S, type = "l")
S
set.seed(123)
n <- 100  # Number of samples
p <- 5    # Number of features
# Generate predictors (features)
X <- matrix(rnorm(n * p), ncol = p)
# Generate true coefficients
theta_true <- c(3, 2, 1, 0, 0)
# Generate response variable
y <- X %*% theta_true + rnorm(n)
lambda <- 1
iter <- 500
mu <- 1.99/(max(eigen(X%*%t(X))$values) + 0.001)
theta_start <- c(7,5,3,9,1)
theta <- matrix(0, nrow = iter, ncol = length(theta_true))
S <- numeric(length = iter)
grad_fn <- function(mat, data, value)
{
grad = t(mat)%*%(mat%*%value - data)
return(grad)
}
prox_func <- function(u, lambda) {       ####  u is a vector
return(sign(u)*sapply(u, FUN=function(x) {max(abs(x)-lambda,0)}))
}
theta[1,] <- theta_start
for (i in 2:iter)
{
gradval <- grad_fn(X, y, theta[i-1,])
z <- prox_func(theta[i-1,] - mu*gradval, mu*lambda)
S1 <- max(max(abs(gradval)) - lambda, 0)
S2 <- abs(-t(gradval)%*%theta[i-1,] - sum(abs(theta[i-1,])))
S[i-1] <- max(S1, S2)
theta[i,] <- z
}
iter_nos <- seq(1:iter)
plot(iter_nos, log(S), type = "l")
set.seed(123)
n <- 100  # Number of samples
p <- 5    # Number of features
# Generate predictors (features)
X <- matrix(rnorm(n * p), ncol = p)
# Generate true coefficients
theta_true <- c(3, 2, 1, 0, 0)
# Generate response variable
y <- X %*% theta_true + rnorm(n)
lambda <- 1
iter <- 500
mu <- 1.99/(max(eigen(X%*%t(X))$values) + 0.001)
theta_start <- c(7,5,3,9,1)
theta <- matrix(0, nrow = iter, ncol = length(theta_true))
S <- numeric(length = iter)
grad_fn <- function(mat, data, value)
{
grad = t(mat)%*%(mat%*%value - data)
return(grad)
}
prox_func <- function(u, lambda) {       ####  u is a vector
return(sign(u)*sapply(u, FUN=function(x) {max(abs(x)-lambda,0)}))
}
theta[1,] <- theta_start
for (i in 2:iter)
{
gradval <- grad_fn(X, y, theta[i-1,])
z <- prox_func(theta[i-1,] - mu*gradval, mu*lambda)
S1 <- max(max(abs(gradval)) - lambda, 0)
S2 <- abs(-t(gradval)%*%theta[i-1,] - sum(abs(theta[i-1,])))
S[i-1] <- max(S1, S2)
theta[i,] <- z
}
iter_nos <- seq(1:iter)
plot(iter_nos, S, type = "l")
source("nuclear_norm_functions.R")
setwd("~/Documents/GitHub/Proximal_IS/NuclearNorm")
######## Poisson random effects run ##########
source("Poisson_functions.R")
setwd("~/Documents/GitHub/Proximal_IS/Poisson_random_effects_model")
######## Poisson random effects run ##########
source("Poisson_functions.R")
lambda <- 0.001
eta_start <- log(rowMeans(data)+1)
mu_start <- mean(eta_start)
iter <- 1e3
delta_mym <- 0.0032
delta_pxm <- 0.00065
delta_mybark <- 0.003
delta_pxbark <- 0.0006
output_poisson <- list()
parallel::detectCores()
num_cores <- 3
doParallel::registerDoParallel(cores = num_cores)
reps <- 3
output_poisson <- foreach(b = 1:reps) %dopar% {
################  MALA  ##################
ismala <- mymala(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_mym, data)
pxmala <- px.mala(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_pxm, data)
mala_chain <- matrix(unlist(ismala[[1]]), nrow = iter, ncol = I+1)
weights_ism <- exp(as.numeric(unlist(ismala[[2]])))
n_eff_mala <- (mean(weights_ism)^2)/mean(weights_ism^2)
# Asymptotic covariance matrix
asymp_covmat_ism <- asymp_covmat_fn(mala_chain, weights_ism)
asymp_covmat_pxm <- mcse.multi(pxmala)$cov
################  Barker  ##################
isbark <- mybarker(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_mybark, data)
pxbark <- px.barker(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_pxbark, data)
bark_chain <- matrix(unlist(isbark[[1]]), nrow = iter, ncol = I+1)
weights_isb <- exp(as.numeric(unlist(isbark[[2]])))
n_eff_bark <- (mean(weights_isb)^2)/mean(weights_isb^2)
# Asymptotic covariance matrix
asymp_covmat_isb <- asymp_covmat_fn(bark_chain, weights_isb)
asymp_covmat_pxb <- mcse.multi(pxbark[[1]])$cov
################  HMC  ##################
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.05, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.05, L=10)
hmc_chain <- matrix(unlist(my.hmc[[1]]), nrow = iter, ncol = I+1)
weights_hmc <- as.numeric(unlist(my.hmc[[2]]))
n_eff_hmc <- (mean(weights_hmc)^2)/mean(weights_hmc^2)
# Asymptotic covariance matrix
asymp_covmat_ishmc <- asymp_covmat_fn(hmc_chain, weights)
asymp_covmat_pxhmc <- mcse.multi(px.hmc[[1]])$cov   # PxMALA asymptotic variance
list(asymp_covmat_ism, asymp_covmat_pxm, asymp_covmat_isb, asymp_covmat_pxb,
asymp_covmat_ishmc, asymp_covmat_pxhmc, n_eff_mala, n_eff_bark, n_eff_hmc)
}
######## Poisson random effects run ##########
source("Poisson_functions.R")
lambda <- 0.001
eta_start <- log(rowMeans(data)+1)
mu_start <- mean(eta_start)
iter <- 1e3
delta_mym <- 0.0032
delta_pxm <- 0.00065
delta_mybark <- 0.003
delta_pxbark <- 0.0006
output_poisson <- list()
parallel::detectCores()
num_cores <- 3
doParallel::registerDoParallel(cores = num_cores)
reps <- 3
output_poisson <- foreach(b = 1:reps) %dopar% {
################  MALA  ##################
ismala <- mymala(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_mym, data)
pxmala <- px.mala(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_pxm, data)
mala_chain <- matrix(unlist(ismala[[1]]), nrow = iter, ncol = I+1)
weights_ism <- exp(as.numeric(unlist(ismala[[2]])))
n_eff_mala <- (mean(weights_ism)^2)/mean(weights_ism^2)
# Asymptotic covariance matrix
asymp_covmat_ism <- asymp_covmat_fn(mala_chain, weights_ism)
asymp_covmat_pxm <- mcse.multi(pxmala)$cov
################  Barker  ##################
isbark <- mybarker(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_mybark, data)
pxbark <- px.barker(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_pxbark, data)
bark_chain <- matrix(unlist(isbark[[1]]), nrow = iter, ncol = I+1)
weights_isb <- exp(as.numeric(unlist(isbark[[2]])))
n_eff_bark <- (mean(weights_isb)^2)/mean(weights_isb^2)
# Asymptotic covariance matrix
asymp_covmat_isb <- asymp_covmat_fn(bark_chain, weights_isb)
asymp_covmat_pxb <- mcse.multi(pxbark[[1]])$cov
################  HMC  ##################
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.05, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.05, L=10)
hmc_chain <- matrix(unlist(my.hmc[[1]]), nrow = iter, ncol = I+1)
weights_hmc <- as.numeric(unlist(my.hmc[[2]]))
n_eff_hmc <- (mean(weights_hmc)^2)/mean(weights_hmc^2)
# Asymptotic covariance matrix
asymp_covmat_ishmc <- asymp_covmat_fn(hmc_chain, weights)
asymp_covmat_pxhmc <- mcse.multi(px.hmc[[1]])$cov   # PxMALA asymptotic variance
list(asymp_covmat_ism, asymp_covmat_pxm, asymp_covmat_isb, asymp_covmat_pxb,
asymp_covmat_ishmc, asymp_covmat_pxhmc, n_eff_mala, n_eff_bark, n_eff_hmc)
}
ismala <- mymala(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_mym, data)
pxmala <- px.mala(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_pxm, data)
mala_chain <- matrix(unlist(ismala[[1]]), nrow = iter, ncol = I+1)
weights_ism <- exp(as.numeric(unlist(ismala[[2]])))
n_eff_mala <- (mean(weights_ism)^2)/mean(weights_ism^2)
# Asymptotic covariance matrix
asymp_covmat_ism <- asymp_covmat_fn(mala_chain, weights_ism)
asymp_covmat_pxm <- mcse.multi(pxmala)$cov
isbark <- mybarker(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_mybark, data)
pxbark <- px.barker(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_pxbark, data)
bark_chain <- matrix(unlist(isbark[[1]]), nrow = iter, ncol = I+1)
weights_isb <- exp(as.numeric(unlist(isbark[[2]])))
n_eff_bark <- (mean(weights_isb)^2)/mean(weights_isb^2)
# Asymptotic covariance matrix
asymp_covmat_isb <- asymp_covmat_fn(bark_chain, weights_isb)
asymp_covmat_pxb <- mcse.multi(pxbark[[1]])$cov
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.05, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.05, L=10)
hmc_chain <- matrix(unlist(my.hmc[[1]]), nrow = iter, ncol = I+1)
weights_hmc <- as.numeric(unlist(my.hmc[[2]]))
n_eff_hmc <- (mean(weights_hmc)^2)/mean(weights_hmc^2)
,
# Asymptotic covariance matrix
asymp_covmat_ishmc <- asymp_covmat_fn(hmc_chain, weights_hmc)
asymp_covmat_pxhmc <- mcse.multi(px.hmc[[1]])$cov   # PxMALA asymptotic variance
list(asymp_covmat_ism, asymp_covmat_pxm, asymp_covmat_isb, asymp_covmat_pxb,
asymp_covmat_ishmc, asymp_covmat_pxhmc, n_eff_mala, n_eff_bark, n_eff_hmc)
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.05, L=10)
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.08, L=10)
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.06, L=10)
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.065, L=10)
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.062, L=10)
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.062, L=10)
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.062, L=10)
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.06, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.05, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.06, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.04, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.035, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.03, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.02, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.01, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.008, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.002, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.003, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.0025, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.002, L=10)
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.06, L=10)
######## Poisson random effects run ##########
source("Poisson_functions.R")
lambda <- 0.001
eta_start <- log(rowMeans(data)+1)
mu_start <- mean(eta_start)
iter <- 1e3
delta_mym <- 0.0032
delta_pxm <- 0.00065
delta_mybark <- 0.003
delta_pxbark <- 0.0006
output_poisson <- list()
parallel::detectCores()
num_cores <- 3
doParallel::registerDoParallel(cores = num_cores)
reps <- 3
output_poisson <- foreach(b = 1:reps) %dopar% {
################  MALA  ##################
ismala <- mymala(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_mym, data)
pxmala <- px.mala(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_pxm, data)
mala_chain <- matrix(unlist(ismala[[1]]), nrow = iter, ncol = I+1)
weights_ism <- exp(as.numeric(unlist(ismala[[2]])))
n_eff_mala <- (mean(weights_ism)^2)/mean(weights_ism^2)
# Asymptotic covariance matrix
asymp_covmat_ism <- asymp_covmat_fn(mala_chain, weights_ism)
asymp_covmat_pxm <- mcse.multi(pxmala)$cov
################  Barker  ##################
isbark <- mybarker(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_mybark, data)
pxbark <- px.barker(eta_start, mu_start, lambda, sigma_eta, iter = iter, delta = delta_pxbark, data)
bark_chain <- matrix(unlist(isbark[[1]]), nrow = iter, ncol = I+1)
weights_isb <- exp(as.numeric(unlist(isbark[[2]])))
n_eff_bark <- (mean(weights_isb)^2)/mean(weights_isb^2)
# Asymptotic covariance matrix
asymp_covmat_isb <- asymp_covmat_fn(bark_chain, weights_isb)
asymp_covmat_pxb <- mcse.multi(pxbark[[1]])$cov
################  HMC  ##################
my.hmc <- myhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.06, L=10)
px.hmc <- pxhmc(eta_start, mu_start,lambda, sigma_eta, iter = iter, data, eps_hmc=0.002, L=10)
hmc_chain <- matrix(unlist(my.hmc[[1]]), nrow = iter, ncol = I+1)
weights_hmc <- as.numeric(unlist(my.hmc[[2]]))
n_eff_hmc <- (mean(weights_hmc)^2)/mean(weights_hmc^2)
# Asymptotic covariance matrix
asymp_covmat_ishmc <- asymp_covmat_fn(hmc_chain, weights_hmc)
asymp_covmat_pxhmc <- mcse.multi(px.hmc[[1]])$cov   # PxMALA asymptotic variance
list(asymp_covmat_ism, asymp_covmat_pxm, asymp_covmat_isb, asymp_covmat_pxb,
asymp_covmat_ishmc, asymp_covmat_pxhmc, n_eff_mala, n_eff_bark, n_eff_hmc)
}
save(output_poisson, file = "output_poisson.Rdata")
load("~/Documents/GitHub/Proximal_IS/Poisson_random_effects_model/output_poisson.Rdata")
output_poisson[[1]]
output_poisson[[1]][[8]]
output_poisson[[1]][[9]]
